\section{Preliminary Experiments}

\begin{table*}
  \begin{centering}
  \begin{tabular}{l||r|r|r||r|r|r||r|r|r}
    & \multicolumn{3}{|c||}{Distinct Faults} & \multicolumn{3}{|c||}{Statement Coverage} &
                                                                    \multicolumn{3}{|c}{Branch Coverage} \\
    \hline
  Method & Min & Max  & Avg & Min & Max & Avg
                                                                  
  & Min & Max & Avg \\
    \hline
    \hline
  AFL on program only & 3 & 5 & 4.2 & 79.86\% & 84.37\% & 81.73\% &
                                                                    78.36\%
                                  & 81.35\% & 80.40\%\\
    \hline
    \hline
  AFL on random mutants, non-cumulative  & 6 & 7 & 6.4 & 80.04\% &
                                                                   84.90\%
                      & 81.70\% & 79.85\% & 82.58\% & 80.70\%\\
  \hline
  AFL on random mutants, cumulative/sequential & 6 & 7 & 6.2 & 80.21\%
                                                               &
                                                                 84.90\%
                      & 81.77\%
                            & 80.10\% & 82.34\% & 80.90\%\\
    \hline
    \hline
    AFL on prioritized mutants, non-cumulative  & 6 & 7 & 6.2 &
                                                                81.25\%
               & 84.37\% & 82.39\% & 80.60\% & 81.84\% & 81.20\% \\
    \hline
    AFL on prioritized mutants, cumulative/sequential  & 6 & 7 & 6.2 &
    81.25\% & 84.90\% & 83.16\% & 80.10\% & 82.58\% & 81.39\%\\    
  \hline
  \end{tabular}
\end{centering}
\label{tab:prelim}
\caption{Results for preliminary experiments}
\end{table*}

Table \ref{tab:prelim} shows results of fuzzing the {\tt fuzzgoat.c}
(\url{https://github.com/fuzzstati0n/fuzzgoat}) benchmark program for
fuzzers, with and without using mutants to aid the fuzzing.  Each
technique was used in 5 fuzzing attempts of 10 hours each.  The
baseline for comparison is the latest Google release of  AFL on the {\tt fuzzgoat} program for 10
hours, with no time spent in any effort other than fuzzing {\tt
  fuzzgoat}.  The other approaches apply the basic methods for using
mutants described above, for five hours, then fuzz using the resulting
corpus for another five hours.  These approaches all spend a small
fraction of the fuzzing budget restarting AFL and processing
already-generated inputs (e.g., to make sure they don't crash the
original program, even if they did not crash a mutant), rather than
fuzzing either {\tt fuzzgoat} or a mutant.  The budget for fuzzing
each mutant is fixed at five minutes, so only about 60 of the nearly
3,800 mutants of {\tt fuzzgoat.c} can be fuzzed.  For the first two
mutant runs, these mutants were chosen randomly each time; the second
two runs used a fixed set of mutants, based on the default mutant
prioritization scheme provided by the Universal Mutator.  Fault
detection was uniformly better for all mutant-based approaches than
for fuzzing without mutants; the minimum number of detected faults was
better than the maximum number of faults found without using mutants.
Code coverage results were more ambigious, but the limited data
suggests the prioritized mutant approaches may be more consistent in
hitting hard-to-teach code than the other methods.

Coverage differences were not statistically significant by Mann
Whitney U test, but bug count differences between all mutant-based methods and AFL
without mutants were significant with $p$-value $< 0.006$.
