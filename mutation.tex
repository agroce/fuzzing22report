\section{Fuzzing the Mutants, in Detail}


\subsection{Mutation Testing}

Mutation
testing~\cite{MutationSurvey,budd1979mutation,demillo1978hints} is an
approach to evaluating and improving tests.  Mutation testing
introduces small syntactic changes into a program, under the
assumption that if the original program was correct, then a program
with slightly different semantics will be incorrect, and should be
detected by effective tests.  Mutation testing is used in software
engineering research, occasionally in industry at-scale, and in some
critical open-source work~\cite{mutKernel,mutGoogle,mutFacebook}.

A mutation testing approach is defined by a set of mutation operators.
Such operators vary widely in the literature, though a few, such as
deleting a small portion of code (such as a statement), negating a
conditonal, or replacing arithmetic and relational operations (e.g.,
changing {\tt +} to {\tt -} or {\tt ==} to {\tt <=}), are very widely
used.


In principle, the ways in which mutants could be incorporated into a
fuzzing process are almost unlimited.  However, the basic approach can
be simplified by considering the fuzzing of mutants as a preparatory
stage for fuzzing the target, as in the introductory example.  The
simplest such approach is to split a given fixed time-budget for
fuzzing into two equal parts.
First, fuzz the mutants.  Then, collect an input corpus from that
fuzzing, and fuzz the target program as usual, but for half of the
desired overall time.

\subsection{Fuzzing: Two Key Decisions}

Given a set of all mutants of a target program, and a decision to
split a given fuzzing budget into a mutant-fuzzing stage followed by a
target-fuzzing stage, there are two major decisions to be made: how to
select a subset of mutants, and how to carry out fuzzing the chosen
mutants.

\subsubsection{Choosing the Mutants}

First, there needs to be some source of mutants.  For generating
mutants, we use the regular-expression-based Universal Mutator
\cite{regexpMut} (\url{https://github.com/agroce/universalmutator}),
which provides a wide variety of source-level mutants for almost any
widely used programming language, and has been used extensively to
mutate C, C++, Java, Python, and Solidity code.  The latest release of
the Universal Mutator is also able to use the Comby \cite{combypaper}
tool (\url{https://github.com/comby-tools/comby}) to generate some
mutants hard to express as regular expressions, and to prune mutants
that are certain to be invalid more efficiently.  Any mutation testing
tool should work, in principle, although if the fuzzer requires the
program to be compiled with special instrumentation, then it is
necessary to use source code mutants, rather than bytecode or
binary/LLVM bitcode mutants.

For most programs, reasonable (e.g., 24 hour) fuzzing budgets, and
approaches to fuzzing mutants discussed below, it is not possible to
fuzz all the mutants of the target program.  For instance, if a
program has a mere 1,000 lines of code, and 2,000 mutants (not an
implausible number), a 12 hour mutant fuzzing budget where each mutant
is fuzzed for five minutes only allows fuzzing of 144 mutants, less
than 1\% of the total mutants.  Two obvious options offer themselves:
the first of these is
purely random selection of mutants, under the assumption that we have
no simple way to predict the good mutants, and that good mutants will
often be redundant.  For the second point, consider the example from
the introduction.  While less effective than removing the {\tt return}
statement, negating the condition, changing it to a constant false, or
modifying a constant return value inside {\tt hard1} may all allow
progress to be made on {\tt hard2} without first satisfying {\tt
  hard1}.  Other changes might relax the most difficult aspects of
{\tt hard1} allowing progress on the easier aspects of the condition,
and thus progress on {\tt hard2}.  Alternatively, even if we cannot
predict the best mutants, it might be reasonable to try to diversify
the mutants selected using some kind of prioritization.  In
particular, in our recent work on using mutants to evaluate static
analysis tools \cite{QRS2021}, we proposed a scheme for ordering
mutants for humans to examine.  

The mutant prioritization
uses Gonzalez' Furthest-Point-First \cite{Gonzalez} (FPF) algorithm
to \emph{rank} mutants, as earlier work had used it to rank test cases for identifying faults \cite{PLDI13}.
An
FPF ranking requires a distance metric $d$, and ranks items so that
dissimilar ones appear earlier.  FPF is a
greedy algorithm that proceeds by repeatedly adding the item with the
\emph{maximum minimum distance to all previously ranked items}. Given an
initial seed item $r_0$, a set $S$ of items to rank, and a distance
metric $d$, FPF computes $r_i$ as
$s \in S: \forall s' \in S: min_{ j < i}(d(s,r_j)) \geq min_{j <
  i}(d(s',r_j))$.  The condition on $s$ is obviously true when
$s = s'$, or when $s' = r_j$ for some $j < i$; the other cases for
$s'$ force selection of \emph{some}
max-min-distance $s$.


The Universal Mutator \cite{regexpMut} tool's FPF metric $d$ is
the sum of a set of measurements.  First, it adds a similarity
ratio based on Levenshtein distance \cite{lev} for (1) the \emph{changes} (Levenshtein edits) from
the original source code elements to
the two mutants,  (2) the two original source code elements changed (in
general, lines), and (3) the actual output mutant code.  These are
weighted with multipliers of 5.0, 0.1, and 0.1, respectively; the type
of change (mutation operator, roughly) dominates this part of the
distance, because it best describes ``what the mutant did''; however,
because many mutants will have the same change (e.g., changing {\tt +}
to {\tt -}, the other values decide many cases.
%The Python
%{\tt Levenshtein} library's similarity ratio is used, as it is based
%on true minimal string edits; it reports similarity ratios between 0.0
%and 1.0.
The metric also incorporates the distance in the source
code between the locations of two mutants.  If the mutants are to
different files, this adds 0.5; it also adds 0.25
times the number of source lines separating the two mutants if they
are in the same file, divided by 10, but caps the amount added at
0.25.  The full metric, therefore is:

$$ 5.0 \times r(\mathit{edit}_1, \mathit{edit}_2) + 0.1 \times r(\mathit{source}_1, \mathit{source}_2) +$$
$$0.1 \times r(\mathit{mutant}_1, \mathit{mutant}_2) + 0.5 \times \mathit{not\_same\_file} +$$
$$max(0.25, \frac{\mathit{line\_dist}(\mathit{mutant}_1, \mathit{mutant}_2)}{10})$$

\noindent Where $r$ is a Levenshtein-based string similarity ratio,
$\mathit{line\_dist}$ is the distance in a source file between
two locations, in lines (zero if the locations are in different
files), and $\mathit{not\_same\_file}$ is 0/1.

The effectiveness of prioritization is an open question; for the problem of determining mutation score, it is known that mutation selection strategies can sometimes be actively harmful, less effective than purely random selection \cite{MutReduct}.  However, the statistical properties that make purely random selection attractive in predicting mutation score are not as important for using mutants to aid fuzzing.

\paragraph{Alternative Prioritizations.}  The above prioritization scheme has the
appeal that it is computable given only the source code and mutants,
and requires no deeper program analysis, dynamic information, or
integration with a particular fuzzer.  However, an obvious alternative
is to prioritize mutants according to their proximity to the
\emph{coverage frontier} of an ongoing fuzzing effort.  That is,
mutants that change code near (in the program-dependence-graph or some other structural representation)  \emph{executed branches where both sides have not been taken} would be given higher
priority.  Mutants of code that is well-covered, on the other hand, or, alternatively, mutants of
code that is deep within completely-uncovered code,
would be lowered in priority.  If we imagine the example proposed in the
introduction to include a large amount of additional code, it is easy
to see that this would likely prioritize the mutation of the {\tt
  return} statement after {\tt hard1}.

There are some drawbacks to this approach, however.  First, the
prioritization may not be as obviously good as it seems at first.
Imagine that the {\tt hard1} condition is indeed on the coverage
frontier, but that a large amount of additional easy-to-cover but branch-heavy code  is present after
the {\tt hard1} branch is taken but before the {\tt return 0} statement.  The {\tt
  return} statement will be a low-priority mutant, since it is not at
all close to the coverage frontier!  Negating the {\tt hard1}
condition, of course, may also be helpful, but will not have the very
useful feature of allowing progress on {\tt hard1} and {\tt hard2} at
the same time.  Furthermore, this approach requires previous fuzzing
data, and in particular the computation of the coverage frontier.

Other prioritizations are also possible; for example, if we have
existing mutation testing results, it may be that mutants that have
been killed are more useful in fuzzing, since they clearly produce a
semantic change.  Equivalent mutants are harmless, but also useless.

\paragraph{Full Mutant Analysis, Continuous Mutant Analysis:} Finally, for especially critical fuzzing targets, especially those
that are continuously fuzzed in systems such as Google's OSS-Fuzz
(\url{https://github.com/google/oss-fuzz}), it may be feasible to
spend the resources to fuzz \emph{all} program mutants, both in order
to identify undetected mutants and to collect the full corpus of
inputs generated using mutants.  In fact, a CI-style continuous
fuzzing effort could in principle alternative fuzzing the target
program with a rolling sequence of mutants (ro at least those that ever generated useful
inputs), in practice elminating the clear demarction between fuzzing
mutants and fuzzing the target.

Finally, while we do not consider the problem here, in repeated efforts it
might be useful to reject some mutants as useless based on past
results.  E.g., if a mutant causes the program to always crash almost
immediately, and so a fuzzer generates many crashes (with only one
signature) but few or no
differing program paths, then the mutant is almost certainly not worth
fuzzing again.

\subsubsection{Using the Mutants}

The second key choice is how to \emph{use} the chosen mutants.
Assuming a fixed fuzzing budget per mutant, the most
basic choice is whether to fuzz each mutant ``from scratch'' (possibly using any existing corpus for
fuzzing the target), which we call non-cumulative/parallel fuzzing,  or to use each mutant's output corpus to seed the next mutant, which we call cumulative/sequential fuzzing.  The cumulative/sequential
approach has two potential advantages:

\begin{enumerate}
\item Many mutants that are fuzzed will potentially benefit from
the already-fuzzed mutants, so hitting a key location that has been
mutated may be more likely; this is based on the same argument as used to support
the approach in general.
\item The final corpus from the last-fuzzed mutant will contain few redundancies, reducing processing or
fuzzer startup time for the actual target.
\end{enumerate}

On the other hand, cumulative fuzzing forces processing of the corpus
after each mutant to remove inputs causing the next mutant to crash,
and, more importantly, prevents fuzzing mutants in parallel.  The
processing cost is due to the fact that before fuzzing a mutant or the
target, any input corpus needs, for the AFL fuzzer at least, to be
pruned, removing any crashing inputs that did not crash the previous
mutant\footnote{These pruned inputs should be preserved and run
  against the actual target program, as they may represent uniquely
  detected faults.}  Removing these sequentially, rather than in a
single batch after all mutants, may remove inputs that could have been
useful for some mutant they do not crash in the future, but re-trying
all inputs for each mutant is expensive.

When only one CPU is available for fuzzing, the sequential vs. parallel nature of the approaches does not matter, but if many CPUs are available, then fuzzing many mutants at once is an obviously attractive proposition.  While the total computing resources required to fuzz the same number of mutants are constant, that one approach is (embarrassingly) parallel is a significant advantage in modern multicore contexts.  In fact, fuzzing mutants to some extent offers a simple solution to the problems of work division and communication overhead that trouble parallel fuzzing in general \cite{wang2021facilitating}.

There are other minor variations.  For instance, if the program under
test has changed since the generation of any existing corpus, it may
be useful to run a fuzzing stage on the target program to help seed
the mutant fuzzing efforts, for the non-cumulative case.  In the
cumulative case, this is unlikely to be helpful, as early mutants will
likely include near-equivalent programs, yielding the same effect with the added advantage of the opportunity offered by mutants.
