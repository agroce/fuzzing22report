\section{Introduction}


Consider the problem of fuzzing a program whose structure is as
follows:

\begin{code}
  if (!hard1(input)) \{
      return 0;
  \}
  if (!hard2(input)) \{
      return 0;
  \}
  crash();   
\end{code}

Assume that conditions {\tt hard1} and {\tt hard2} are independent
constraints on an input, both of which are difficult to achieve.  A
normal mutation-based
fuzzer such as AFL or libFuzzer attempting to reach the call to {\tt crash} will generally
first have to construct an input satsifying {\tt hard1} and then,
while preserving {\tt hard1}, modify that input until it also
satisfies {\tt hard2}.  A key point to note is that if the fuzzer
accidentally produces an input that is a good start on satisfying {\tt
  hard2}, or even completely satisfies {\tt hard2}, such an input will
be discarded, because execution never reaches the implementation of
{\tt hard2} unless {\tt hard1} has already been ``solved.''  Even
though the fuzzer must eventually satisfy both conditions, it can only
work on them in the execution order.  By analogy, consider the problem
of rolling a pair of \emph{ordered} dice.  If the goal is to roll two values above
five, and you are allowed to ``save'' a good roll of the first of the
two dice and use it in future attempts, the problem is easier than if
the dice have to be rolled from scratch each time.  However, it is not
as easy as if good rolls of the second die can also be saved!

If we fuzz a program without the first {\tt return} statement:

\begin{code}
  if (!hard1(input)) \{
    /* return 0; */
  \}
  if (!hard2(input)) \{
      return 0;
  \}
  crash();   
\end{code}

\noindent then progress towards both {\tt hard1} and {\tt hard2} can
be made \emph{at the same time}, independently, in any order.  If a generated input progresses
achievement of either {\tt hard1} or {\tt hard2} it will be kept and
used in further fuzzing.   Of course, \emph{crashing inputs} for this
modified program are seldom crashing inputs for the
original program.  However, given a partial or total solution to {\tt
  hard1} and a partial or total solution to {\tt hard2}, it should be
much easier for a fuzzer to construct a crashing input for the
original program.  This is a very simple example of a case where
fuzzing a similar program can produce inputs such that 1) they help fuzz the
actual program under test and 2) those inputs are much harder, or
essentially impossible, to
generate for the original program using the fuzzer.

Three points are important to note about this approach: first, fuzzing an arbitrary program would be of no use here.  Inputs useful in exploring that program would likely be useless in exploring the real target of fuzzing.  Second, if a modification has little semantic impact on the original program, then fuzzing that variation is, to a large extent, the same as fuzzing the original program, with the only cost being some additional fuzzer logistics overhead.  Finally, predicting which program variants will aid fuzzing seems inherently hard.  In this case, removing a statemeent was extremely useful; in other cases breaking out of a loop before it fails a check might be important, or turning a condition into a constant true --- or constant false!  Analysis capable of detecting reliably ``good'' changes seems likely to be fundamentally about as hard as fuzzing itself, or symbolic execution.  Recall however, that many variants that are not useful will also be harmless, in that they amount to simply fuzzing the target.  What we need is a source of similar programs that will include the (perhaps rare) high-value variants (such as removing the {\tt return} above, and will not include too many programs so dis-similar in semantics they provide no value.

Program \emph{mutants} provide this such variants, by design.  Mutants are designed to show weaknesses in a testing effort, by showing
the ability of a test suite to detect \emph{plausible bugs}.  The majority of such hypothetical bugs must be semantically similar enough to
the original program that a test suite's effectiveness is meaningful for both original and mutated program.  Therefore, most program mutants
will satisfy the condition of being close enough to the target of fuzzing.  Mutants are roughly evenly distributed over a program's source code,
and modify only a single location.  Therefore most uninteresting mutants will generally be harmless, since fuzzing the mutant will be essentially
fuzzing the original program, except for a small number of code paths.  Finally, mutation operators are varied enough to provide a good source
of potentially useful mutants.  Most importantly, almost all mutation tools include at least statement deletion (to remove checks that impede
fuzzing) and conditional changes (negation, and replacement with constant false and constant true).  These are the variants with the most
obvious potential.

Additionally, fuzzing program mutants is a \emph{useful activity in itself}.  Mutation testing is increasingly being applied in the real-world.
A program worth fuzzing is probably a program worth examining from the perspective of mutation testing.  Examining mutants not detected by fuzzing
can reveal opportunities to improve a fuzzing effort, either by helping it reach hard-to-cover paths or, more frequently, by improving the oracle
(e.g., adding assertions about invariants a mutant causes to be violated, or even creating a new end-to-end fuzzing harness when a fault is
not exposed by fuzzing only isolated components of a program).
